# -*- coding: utf-8 -*-
"""cyclegan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bexRp56spEUamzFUFcCWpABs6crC4J_Q
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/cyclegan/
"""
!pip install --upgrade --force-reinstall --no-deps albumentations pipreqs yarg

!pip install libtiff

!pip install opencv-python-headless imgaug
"""
from sklearn.model_selection import train_test_split
import pandas as pd
import numpy as np
import time
import sys
from itertools import product
import cv2
import os
import matplotlib.pyplot as plt
from libtiff import TIFF

def mean_normalize(image):
  std_lst = []
  mean_lst = []
  for idx in range(image.shape[2]):
    std_chan = np.std(image[:,:,idx])
    mean_chan = np.mean(image[:,:,idx])
    std_lst.append(std_chan)
    mean_lst.append(mean_chan)

  std_img = np.array([std_lst])
  mean_img = np.array([mean_lst])
  norm_img = (image - mean_img)/std_img
  return std_img, mean_img, norm_img

IMAGE_SIZE = 256

import random
imgname_list = os.listdir('/content/drive/MyDrive/Anshul files/Inria_datasets/images/')
imgname_list = sorted(imgname_list)

mask_list = os.listdir('/content/drive/MyDrive/Anshul files/Inria_datasets/gt/')
mask_list = sorted(mask_list)


tile_sizex = IMAGE_SIZE
tile_sizey = IMAGE_SIZE

min_feature_cnt = 1

print(len(imgname_list))
print(len(mask_list))

i=1

imageseg = dict()

img_folder_path = '/content/drive/MyDrive/Anshul files/Inria_datasets/images/'
for img_name in imgname_list:
  print(img_name)

  img_name = img_folder_path+img_name
  tifinimg = TIFF.open(img_name)
  inimg = tifinimg.read_image()
  TIFF.close(tifinimg)

  img_dtype = type(inimg[0,0,0])

  print(inimg.shape)

  (H,W,Ch) = inimg.shape

  (H_delta,W_delta) = 0,0

  if (H % tile_sizey) != 0:
    H_delta = tile_sizey - (H % tile_sizey)
    #print(H_delta)
  if (W % tile_sizex) != 0:
    W_delta = tile_sizex - (W % tile_sizex)
    #print(W_delta)

  #print(img_dtype)

  IMG_FILL_VALUE = np.max(inimg)

  top, bottom, left, right = 0, H_delta, 0, W_delta

  inimg_new =  np.ones((H+H_delta, W+W_delta,Ch), dtype=img_dtype) * IMG_FILL_VALUE
  inimg_new[:H,:W,:] = inimg

  #_, _, inimg_new = mean_normalize(inimg_new)
  inimg_new = inimg_new/255
  offsets = product(range(0, W, tile_sizex), range(0, H, tile_sizey))

  cnt = 1

  for row_off,col_off in offsets:
    print("Img:{}. (Row:Col) = ({}:{})".format(cnt,row_off,col_off))

    col_start, col_end, row_start, row_end = col_off, col_off+tile_sizey-1, row_off, row_off+tile_sizex-1

    imgtile = inimg_new[col_start:col_end+1,row_start:row_end+1,:]
    imageseg['{}-{}-{}'.format(i, row_off,col_off)] = imgtile

    cnt = cnt + 1

  i=i+1

  if i>2:
    break
    #print(imgtile.shape)

len(imageseg)

i=1

imageseg2 = dict()
trainx_list = []
trainy_list = []

mask_folder_path = '/content/drive/MyDrive/Anshul files/Inria_datasets/gt/'
for mask_name in mask_list:
  print(mask_name)

  img_name = mask_folder_path+mask_name
  tifinimg = TIFF.open(img_name)
  inmask = tifinimg.read_image()
  TIFF.close(tifinimg)

  mask_dtype = type(inmask[0,0])

  print(mask_dtype.shape)

  (H2,W2) = inmask.shape

  (H_delta2,W_delta2) = 0,0

  if (H2 % tile_sizey) != 0:
    H_delta2 = tile_sizey - (H2 % tile_sizey)
  if (W2 % tile_sizex) != 0:
    W_delta2 = tile_sizex - (W2 % tile_sizex)

  top2, bottom2, left2, right2 = 0, H_delta2, 0, W_delta2
  inmask_new =  cv2.copyMakeBorder(inmask, top2, bottom2, left2, right2, cv2.BORDER_CONSTANT, value=0)
    #print(W_delta)
  mask_minval = np.min(inmask_new)
  mask_maxval = np.max(inmask_new)
  inmask_new = inmask_new / (mask_maxval - mask_minval)

  offsets2 = product(range(0, W2, tile_sizex), range(0, H2, tile_sizey))

  cnt2 = 1
  #print(img_dtype)
  for row_off2,col_off2 in offsets2:
    print("Mask:{}. (Row:Col) = ({}:{})".format(cnt2,row_off2,col_off2))
    col_start2, col_end2, row_start2, row_end2 = col_off2, col_off2+tile_sizey-1, row_off2, row_off2+tile_sizex-1
    imgtile2 = inmask_new[col_start2:col_end2+1,row_start2:row_end2+1]

    imgtile2_org = imgtile2.copy()

    imgtile2 = np.expand_dims(imgtile2, axis=2)
     # shape (1, x_pixels, y_pixels, n_bands)
    imageseg2['{}-{}-{}'.format(i, row_off2,col_off2)] = imgtile2

    if (cv2.countNonZero(imageseg2['{}-{}-{}'.format(i, row_off2,col_off2)])) > min_feature_cnt:

      trainx_list.append(imageseg['{}-{}-{}'.format(i, row_off2,col_off2)])

      trainy_list.append(imgtile2)

  cnt2 = cnt2 + 1

  i=i+1

  if i>2:
    break
    #print(imgtile.shape)

print(len(imageseg2), len(imageseg))

trainx = np.asarray(trainx_list)
trainy = np.asarray(trainy_list)
print(trainx.shape)
print(trainy.shape)

min_samples = min(trainx.shape[0],trainy.shape[0])

print(min_samples)

x_train, x_test, y_train, y_test = train_test_split(trainx[:min_samples], trainy[:min_samples], test_size=0.20, random_state=4)

print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)
print(x_train.shape[1:])

import torch
import albumentations as A
from albumentations.pytorch import ToTensorV2

# some parameters to help in training
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

BATCH_SIZE = 1
LEARNING_RATE = 2e-4
LAMBDA_IDENTITY = 0
LAMBDA_CYCLE = 50
NUM_WORKERS = 0
NUM_EPOCHS = 10
LOAD_MODEL = False
SAVE_MODEL = False
CHECKPOINT_GEN_H = "genh.pth.tar"
CHECKPOINT_GEN_Z = "genz.pth.tar"
CHECKPOINT_CRITIC_H = "critich.pth.tar"
CHECKPOINT_CRITIC_Z = "criticz.pth.tar"

from PIL import Image
import os
from torch.utils.data import Dataset
import numpy as np

import random, torch, os, numpy as np
import torch.nn as nn
import copy



# saving model weights during training.

def save_checkpoint(model, optimizer, filename="my_checkpoint.pth.tar"):
    print("=> Saving checkpoint")
    checkpoint = {
        "state_dict": model.state_dict(),
        "optimizer": optimizer.state_dict(),
    }
    torch.save(checkpoint, filename)

# loading model weights to resume training

def load_checkpoint(checkpoint_file, model, optimizer, lr):
    print("=> Loading checkpoint")
    checkpoint = torch.load(checkpoint_file, map_location=DEVICE)
    model.load_state_dict(checkpoint["state_dict"])
    optimizer.load_state_dict(checkpoint["optimizer"])

    # If we don't do this then it will just have learning rate of old checkpoint
    # and it will lead to many hours of debugging \:
    for param_group in optimizer.param_groups:
        param_group["lr"] = lr

# just seeds for making results reproducible.

def seed_everything(seed=42):
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

seed_everything(42)

# this is the original patch gan implementation from the paper cycleGAN
# I have sent you the model architecture beforehand
# Make suitable changes as you like but keep in mind the shape of output please.



class Block(nn.Module):
    def __init__(self, in_channels, out_channels, stride):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 4, stride, 1, bias=True, padding_mode="reflect"),
            nn.InstanceNorm2d(out_channels),
            nn.LeakyReLU(0.2, inplace=True),
        )

    def forward(self, x):
        return self.conv(x)


class Discriminator(nn.Module):
    def __init__(self, in_channels=1, features=[8, 16, 32, 64, 128, 256, 512]):
        super().__init__()
        self.initial = nn.Sequential(
            nn.Conv2d(
                in_channels,
                features[0],
                kernel_size=4,
                stride=2,
                padding=1,
                padding_mode="reflect",
            ),
            nn.LeakyReLU(0.2, inplace=True),
        )

        layers = []
        in_channels = features[0]
        for feature in features[1:]:
            layers.append(Block(in_channels, feature, stride=1 if feature==features[-1] else 2))
            in_channels = feature
        layers.append(nn.Conv2d(in_channels, 1, kernel_size=4, stride=1, padding=1, padding_mode="reflect"))
        self.model = nn.Sequential(*layers)

    def forward(self, x):
        x = self.initial(x)
        return torch.sigmoid(self.model(x))



# this is just a test function to see if the output shape is correct for the model.

def test():
    x = torch.randn((5, 1, 256, 256))
    model = Discriminator()
    preds = model(x)
    print(preds.shape)
    print(model)

test()

ndf = 64


class newDiscriminator(nn.Module):
    def __init__(self, nc):
        super(newDiscriminator, self).__init__()
        self.main = nn.Sequential(
            # input is (nc) x 64 x 64
            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf) x 32 x 32
            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 2),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*2) x 16 x 16
            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 4),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*4) x 8 x 8
            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 8),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*8) x 4 x 4
            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
        )

    def forward(self, input):
        return self.main(input)


def testnew():
    x = torch.randn((5, 1, 256, 256))
    model = newDiscriminator(nc=1)
    preds = model(x)
    print(preds.shape)
    print(model)

testnew()

# this is the unet implementation

from torch.nn import functional as F


class ConvLayer(nn.Sequential):
    def __init__(self, in_channels:int, out_channels:int):
        super().__init__()
        self.add_module('conv', nn.Conv2d(in_channels, out_channels,
                                           3, padding=1, bias=False))
        self.add_module('norm', nn.BatchNorm2d(out_channels))
        self.add_module('relu', nn.ReLU(inplace=True))


class UNetBlock(nn.Sequential):
    def __init__(self, in_channels:int, out_channels:int):
        super().__init__()
        self.add_module('block1', ConvLayer(in_channels, out_channels))
        self.add_module('block2', ConvLayer(out_channels, out_channels))


class UNet(nn.Module):
    def __init__(self, in_channels:int, out_channels:int, channel_base:int=64):
        super().__init__()
        self.down_layers = nn.ModuleList([])
        n_chan = lambda x: channel_base*2**x
        self.down_layers.append(UNetBlock(in_channels, n_chan(0)))
        for i in range(3):
            self.down_layers.append(UNetBlock(n_chan(i), n_chan(i+1)))
        self.bottleneck = UNetBlock(n_chan(3), n_chan(4))
        self.up_layers = nn.ModuleList([])
        for i in reversed(range(1, 4)):
            self.up_layers.append(UNetBlock(n_chan(i+1)+n_chan(i), n_chan(i)))
        self.up_layers.append(nn.Sequential(
            UNetBlock(n_chan(1)+n_chan(0), n_chan(0),),
            nn.Conv2d(n_chan(0), out_channels, 1)))

    @staticmethod
    def interp_cat(x, skip):
        x = F.interpolate(x, skip.shape[2:], mode='bilinear', align_corners=True)
        return torch.cat((x, skip), 1)

    def forward(self, x):
        skip_connections = []
        for down_layer in self.down_layers:
            x = down_layer(x)
            skip_connections.append(x)
            x = F.max_pool2d(x, 2)
        x = self.bottleneck(x)
        for up_layer in self.up_layers:
            skip = skip_connections.pop()
            x = self.interp_cat(x, skip)
            x = up_layer(x)


        return torch.sigmoid(x)


# test function for unet.
def testu():
    img_channels = 3
    img_size = 256
    x = torch.randn((1, 3, img_size, img_size))
    #gen = Generator(img_channels, 9)
    model = UNet(3,1)
    print(model)
    #print(gen(x))

testu()

from torch.utils.data import TensorDataset, DataLoader

x_train_tensor = torch.Tensor(x_train).permute(0, 3, 1, 2)
x_test_tensor = torch.Tensor(x_test).permute(0, 3, 1, 2)
y_train_tensor = torch.Tensor(y_train).permute(0, 3, 1, 2)
y_test_tensor = torch.Tensor(y_test).permute(0, 3, 1, 2)

#x_train_tensor=x_train_tensor.permute(0, 3, 1, 2)

print(x_train_tensor.size())
print(x_test_tensor.shape)
print(y_train_tensor.shape)
print(y_test_tensor.shape)

train_data = TensorDataset(x_train_tensor, y_train_tensor)
val_data = TensorDataset(x_test_tensor, y_test_tensor)

import torch.optim as optim
from tqdm.notebook import tqdm
from torchvision.utils import save_image

def initialize_weights(model):
    # Initializes weights according to the DCGAN paper
    for m in model.modules():
        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):
            nn.init.normal_(m.weight.data, 0.0, 0.01)

g_loss= []

lossmse = nn.MSELoss()
criterion = nn.BCELoss()

def train_fn(disc_Z, gen_Z, gen_H, loader, opt_disc, opt_gen, l1, mse):
    H_reals = 0
    H_fakes = 0
    sum_g_loss = 0
    # tqdm loader bar
    loop = tqdm(loader, leave=True)
    i=1
    for idx, (orig_image, mask_image) in enumerate(loop):
        mask_image = mask_image.to(DEVICE)
        orig_image = orig_image.to(DEVICE)


        # Train Discriminators H and Z
        #with torch.cuda.amp.autocast():
        '''
        fake_orig_image = gen_H(mask_image)
        D_H_real = disc_H(orig_image)
        D_H_fake = disc_H(fake_orig_image.detach())
        H_reals += D_H_real.mean().item()
        H_fakes += D_H_fake.mean().item()
        D_H_real_loss = mse(D_H_real, torch.ones_like(D_H_real))
        D_H_fake_loss = mse(D_H_fake, torch.zeros_like(D_H_fake))
        D_H_loss = D_H_real_loss + D_H_fake_loss
        '''

        fake_mask_image = gen_Z(orig_image)
        D_Z_real = disc_Z(mask_image).reshape(-1)
        D_Z_fake = disc_Z(fake_mask_image.detach()).reshape(-1)
        D_Z_real_loss = criterion(D_Z_real, torch.ones_like(D_Z_real))
        D_Z_fake_loss = criterion(D_Z_fake, torch.zeros_like(D_Z_fake))
        D_Z_loss = D_Z_real_loss + D_Z_fake_loss

        # put it togethor
        D_loss = (D_Z_loss)/2

        disc_Z.zero_grad()
        D_loss.backward()
        opt_disc.step()



        # Train Generators H and Z
        #with torch.cuda.amp.autocast():
        # adversarial loss for both generators
        #D_H_fake = disc_H(fake_orig_image)
        D_Z_fake = disc_Z(fake_mask_image).reshape(-1)
        #loss_G_H = mse(D_H_fake, torch.ones_like(D_H_fake))
        loss_G_Z = criterion(D_Z_fake, torch.ones_like(D_Z_fake))
        loss_mse = lossmse(fake_mask_image, mask_image)
        # cycle loss
        #cycle_mask_image = gen_Z(fake_orig_image)
        #cycle_orig_image = gen_H(fake_mask_image)
        #ycle_mask_image_loss = l1(mask_image, cycle_mask_image)
        #cycle_orig_image_loss = l1(orig_image, cycle_orig_image)


        G_loss = (
            loss_G_Z
            +100*loss_mse
            #+ loss_G_H
            #+ cycle_mask_image_loss * LAMBDA_CYCLE
            #+ cycle_orig_image_loss * LAMBDA_CYCLE

        )
        gen_Z.zero_grad()
        G_loss.backward()
        opt_gen.step()


        if idx % 50 == 0:
            #fake_mask_image = torch.where(fake_mask_image<0.5, 0, 1)
            print(fake_mask_image.shape)
            fake_mask_image = torch.where(fake_mask_image<0.5, 0.0, 1.0)
            #save_image(fake_orig_image, f"saved_images/orig_image_{idx}.png")
            save_image(fake_mask_image, f"saved_images/mask_image_{idx}.png")

        loop.set_postfix(H_real=H_reals/(idx+1), H_fake=H_fakes/(idx+1))
        #sum_g_loss = sum_g_loss + G_loss
        g_loss.append(G_loss)




def main():

    #define models

    #disc_H = newDiscriminator(nc=3).to(DEVICE)
    disc_Z = newDiscriminator(nc=1).to(DEVICE)
    gen_Z = UNet(3, 1).to(DEVICE)
    gen_H = UNet(1, 3).to(DEVICE)
    #initialize_weights(disc_Z)
    #initialize_weights(gen_Z)

    #define adam, betas were dame as paper
    # for generator
    opt_disc = optim.Adam(
        disc_Z.parameters(),
        lr=LEARNING_RATE,
        betas=(0.5, 0.999),
    )

    #for discriminator
    opt_gen = optim.Adam(
        gen_Z.parameters(),
        lr=LEARNING_RATE,
        betas=(0.5, 0.999),
    )

    # define loss functions
    L1 = nn.L1Loss()
    mse = nn.MSELoss()

    # to resume training, make LOAD_Model in config.py to True
    if LOAD_MODEL:
        load_checkpoint(
            CHECKPOINT_GEN_H, gen_H, opt_gen, LEARNING_RATE,
        )
        load_checkpoint(
            CHECKPOINT_GEN_Z, gen_Z, opt_gen, LEARNING_RATE,
        )
        load_checkpoint(
            CHECKPOINT_CRITIC_H, disc_H, opt_disc, LEARNING_RATE,
        )
        load_checkpoint(
            CHECKPOINT_CRITIC_Z, disc_Z, opt_disc, LEARNING_RATE,
        )




    # train data loader
    loader = DataLoader(
        train_data,
        batch_size=BATCH_SIZE,
        num_workers=NUM_WORKERS,
        pin_memory=True
    )


 # train function

    for epoch in range(10):
        train_fn(disc_Z, gen_Z, gen_H, loader, opt_disc, opt_gen, L1, mse)
        # to save the model weights
        if SAVE_MODEL:
            save_checkpoint(gen_H, opt_gen, filename=CHECKPOINT_GEN_H)
            save_checkpoint(gen_Z, opt_gen, filename=CHECKPOINT_GEN_Z)
            save_checkpoint(disc_H, opt_disc, filename=CHECKPOINT_CRITIC_H)
            save_checkpoint(disc_Z, opt_disc, filename=CHECKPOINT_CRITIC_Z)

main()

new_g = []
for x in g_loss:
  x = x.detach().cpu().numpy()
  new_g.append(x)

from matplotlib import pyplot
pyplot.plot(new_g)
