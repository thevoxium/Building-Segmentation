# -*- coding: utf-8 -*-
"""resunettrain.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gCUsThmHgzg-7v1oFqyJyAeVP6zUo4fe
"""

# -*- coding: utf-8 -*-
"""Resunet_pytorch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YoZfk-O8WJoOn9Lp6ngSaII3VwYJSir-
"""

!pip install libtiff opencv-python-headless imgaug

from sklearn.model_selection import train_test_split
import pandas as pd
import numpy as np
import time
import sys
from itertools import product
import cv2
import os
import matplotlib.pyplot as plt
from libtiff import TIFF


import random, torch, os, numpy as np
import torch.nn as nn
import copy
from torch.utils.data import TensorDataset, DataLoader
import torch.optim as optim
from tqdm.notebook import tqdm
from torchvision.utils import save_image
from torch.nn import functional as F

def mean_normalize(image):
  std_lst = []
  mean_lst = []
  for idx in range(image.shape[2]):
    std_chan = np.std(image[:,:,idx])
    mean_chan = np.mean(image[:,:,idx])
    std_lst.append(std_chan)
    mean_lst.append(mean_chan)

  std_img = np.array([std_lst])
  mean_img = np.array([mean_lst])
  norm_img = (image - mean_img)/std_img
  return std_img, mean_img, norm_img

IMAGE_SIZE = 256
LEARNING_RATE = 1e-3
NUM_EPOCHS = 10
BATCH_SIZE = 16
VAL_STEP = 10
IMAGE_INDEX = 35

import random
imgname_list = os.listdir('/content/drive/MyDrive/Anshul files/Inria_datasets/images/')
imgname_list = sorted(imgname_list)

mask_list = os.listdir('/content/drive/MyDrive/Anshul files/Inria_datasets/gt/')
mask_list = sorted(mask_list)


tile_sizex = IMAGE_SIZE
tile_sizey = IMAGE_SIZE

min_feature_cnt = 1

print(len(imgname_list))
print(len(mask_list))

i=1

imageseg = dict()

img_folder_path = '/content/drive/MyDrive/Anshul files/Inria_datasets/images/'
for img_name in imgname_list:
  print(img_name)

  img_name = img_folder_path+img_name
  tifinimg = TIFF.open(img_name)
  inimg = tifinimg.read_image()
  TIFF.close(tifinimg)

  img_dtype = type(inimg[0,0,0])

  print(inimg.shape)

  (H,W,Ch) = inimg.shape

  (H_delta,W_delta) = 0,0

  if (H % tile_sizey) != 0:
    H_delta = tile_sizey - (H % tile_sizey)
    #print(H_delta)
  if (W % tile_sizex) != 0:
    W_delta = tile_sizex - (W % tile_sizex)
    #print(W_delta)

  #print(img_dtype)

  IMG_FILL_VALUE = np.max(inimg)

  top, bottom, left, right = 0, H_delta, 0, W_delta

  inimg_new =  np.ones((H+H_delta, W+W_delta,Ch), dtype=img_dtype) * IMG_FILL_VALUE
  inimg_new[:H,:W,:] = inimg

  #_, _, inimg_new = mean_normalize(inimg_new)
  inimg_new = inimg_new/255
  offsets = product(range(0, W, tile_sizex), range(0, H, tile_sizey))

  cnt = 1

  for row_off,col_off in offsets:
    #print("Img:{}. (Row:Col) = ({}:{})".format(cnt,row_off,col_off))

    col_start, col_end, row_start, row_end = col_off, col_off+tile_sizey-1, row_off, row_off+tile_sizex-1

    imgtile = inimg_new[col_start:col_end+1,row_start:row_end+1,:]
    imageseg['{}-{}-{}'.format(i, row_off,col_off)] = imgtile

    cnt = cnt + 1

  i=i+1

  if i>2:
    break
    #print(imgtile.shape)

i=1

imageseg2 = dict()
trainx_list = []
trainy_list = []

mask_folder_path = '/content/drive/MyDrive/Anshul files/Inria_datasets/gt/'
for mask_name in mask_list:
  print(mask_name)

  img_name = mask_folder_path+mask_name
  tifinimg = TIFF.open(img_name)
  inmask = tifinimg.read_image()
  TIFF.close(tifinimg)

  mask_dtype = type(inmask[0,0])

  print(mask_dtype.shape)

  (H2,W2) = inmask.shape

  (H_delta2,W_delta2) = 0,0

  if (H2 % tile_sizey) != 0:
    H_delta2 = tile_sizey - (H2 % tile_sizey)
  if (W2 % tile_sizex) != 0:
    W_delta2 = tile_sizex - (W2 % tile_sizex)

  top2, bottom2, left2, right2 = 0, H_delta2, 0, W_delta2
  inmask_new =  cv2.copyMakeBorder(inmask, top2, bottom2, left2, right2, cv2.BORDER_CONSTANT, value=0)
    #print(W_delta)
  mask_minval = np.min(inmask_new)
  mask_maxval = np.max(inmask_new)
  inmask_new = inmask_new / (mask_maxval - mask_minval)

  offsets2 = product(range(0, W2, tile_sizex), range(0, H2, tile_sizey))

  cnt2 = 1
  #print(img_dtype)
  for row_off2,col_off2 in offsets2:
    #print("Mask:{}. (Row:Col) = ({}:{})".format(cnt2,row_off2,col_off2))
    col_start2, col_end2, row_start2, row_end2 = col_off2, col_off2+tile_sizey-1, row_off2, row_off2+tile_sizex-1
    imgtile2 = inmask_new[col_start2:col_end2+1,row_start2:row_end2+1]

    imgtile2_org = imgtile2.copy()

    imgtile2 = np.expand_dims(imgtile2, axis=2)
     # shape (1, x_pixels, y_pixels, n_bands)
    imageseg2['{}-{}-{}'.format(i, row_off2,col_off2)] = imgtile2

    if (cv2.countNonZero(imageseg2['{}-{}-{}'.format(i, row_off2,col_off2)])) > min_feature_cnt:

      trainx_list.append(imageseg['{}-{}-{}'.format(i, row_off2,col_off2)])

      trainy_list.append(imgtile2)

  cnt2 = cnt2 + 1

  i=i+1

  if i>2:
    break
    #print(imgtile.shape)

print(len(imageseg2), len(imageseg))

trainx = np.asarray(trainx_list)
trainy = np.asarray(trainy_list)
print(trainx.shape)
print(trainy.shape)

min_samples = min(trainx.shape[0],trainy.shape[0])

print(min_samples)

x_train, x_test, y_train, y_test = train_test_split(trainx[:min_samples], trainy[:min_samples], test_size=0.20, random_state=4)

print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)
print(x_train.shape[1:])

import torch
from torch.utils.data import TensorDataset, DataLoader

x_train_tensor = torch.Tensor(x_train).permute(0, 3, 1, 2)
x_test_tensor = torch.Tensor(x_test).permute(0, 3, 1, 2)
y_train_tensor = torch.Tensor(y_train).permute(0, 3, 1, 2)
y_test_tensor = torch.Tensor(y_test).permute(0, 3, 1, 2)

print(x_train_tensor.size())
print(x_test_tensor.shape)
print(y_train_tensor.shape)
print(y_test_tensor.shape)

train_data = TensorDataset(x_train_tensor, y_train_tensor)
val_data = TensorDataset(x_test_tensor, y_test_tensor)

import torch.optim as optim
import torch.nn as nn
from tqdm.notebook import tqdm
from torchvision.utils import save_image

loader = DataLoader(
        train_data,
        batch_size=BATCH_SIZE,
        num_workers=0,
        pin_memory=True
    )

val_loader = DataLoader(
    val_data,
    batch_size = BATCH_SIZE,
    num_workers = 0,
    pin_memory = True,
)

class ResidualConv(nn.Module):
    def __init__(self, input_dim, output_dim, stride, padding):
        super(ResidualConv, self).__init__()

        self.conv_block = nn.Sequential(
            nn.BatchNorm2d(input_dim),
            nn.ReLU(),
            nn.Conv2d(
                input_dim, output_dim, kernel_size=3, stride=stride, padding=padding
            ),
            nn.BatchNorm2d(output_dim),
            nn.ReLU(),
            nn.Conv2d(output_dim, output_dim, kernel_size=3, padding=1),
        )
        self.conv_skip = nn.Sequential(
            nn.Conv2d(input_dim, output_dim, kernel_size=3, stride=stride, padding=1),
            nn.BatchNorm2d(output_dim),
        )

    def forward(self, x):

        return self.conv_block(x) + self.conv_skip(x)


class Upsample(nn.Module):
    def __init__(self, input_dim, output_dim, kernel, stride):
        super(Upsample, self).__init__()

        self.upsample = nn.ConvTranspose2d(
            input_dim, output_dim, kernel_size=kernel, stride=stride
        )

    def forward(self, x):
        return self.upsample(x)



class ResUnet(nn.Module):
    def __init__(self, channel, filters=[64, 128, 256, 512]):
        super(ResUnet, self).__init__()

        self.input_layer = nn.Sequential(
            nn.Conv2d(channel, filters[0], kernel_size=3, padding=1),
            nn.BatchNorm2d(filters[0]),
            nn.ReLU(),
            nn.Conv2d(filters[0], filters[0], kernel_size=3, padding=1),
        )
        self.input_skip = nn.Sequential(
            nn.Conv2d(channel, filters[0], kernel_size=3, padding=1)
        )

        self.residual_conv_1 = ResidualConv(filters[0], filters[1], 2, 1)
        self.residual_conv_2 = ResidualConv(filters[1], filters[2], 2, 1)

        self.bridge = ResidualConv(filters[2], filters[3], 2, 1)

        self.upsample_1 = Upsample(filters[3], filters[3], 2, 2)
        self.up_residual_conv1 = ResidualConv(filters[3] + filters[2], filters[2], 1, 1)

        self.upsample_2 = Upsample(filters[2], filters[2], 2, 2)
        self.up_residual_conv2 = ResidualConv(filters[2] + filters[1], filters[1], 1, 1)

        self.upsample_3 = Upsample(filters[1], filters[1], 2, 2)
        self.up_residual_conv3 = ResidualConv(filters[1] + filters[0], filters[0], 1, 1)

        self.output_layer = nn.Sequential(
            nn.Conv2d(filters[0], 1, 1, 1),
            nn.Sigmoid(),
        )

    def forward(self, x):
        # Encode
        x1 = self.input_layer(x) + self.input_skip(x)
        x2 = self.residual_conv_1(x1)
        x3 = self.residual_conv_2(x2)
        # Bridge
        x4 = self.bridge(x3)
        # Decode
        x4 = self.upsample_1(x4)
        x5 = torch.cat([x4, x3], dim=1)

        x6 = self.up_residual_conv1(x5)

        x6 = self.upsample_2(x6)
        x7 = torch.cat([x6, x2], dim=1)

        x8 = self.up_residual_conv2(x7)

        x8 = self.upsample_3(x8)
        x9 = torch.cat([x8, x1], dim=1)

        x10 = self.up_residual_conv3(x9)

        output = self.output_layer(x10)

        return output


class ConvLayer(nn.Sequential):
    def __init__(self, in_channels:int, out_channels:int):
        super().__init__()
        self.add_module('conv', nn.Conv2d(in_channels, out_channels,
                                           3, padding=1, bias=False))
        self.add_module('norm', nn.BatchNorm2d(out_channels))
        self.add_module('relu', nn.ReLU(inplace=True))


class UNetBlock(nn.Sequential):
    def __init__(self, in_channels:int, out_channels:int):
        super().__init__()
        self.add_module('block1', ConvLayer(in_channels, out_channels))
        self.add_module('block2', ConvLayer(out_channels, out_channels))


class UNet(nn.Module):
    def __init__(self, in_channels:int, out_channels:int, channel_base:int=64):
        super().__init__()
        self.down_layers = nn.ModuleList([])
        n_chan = lambda x: channel_base*2**x
        self.down_layers.append(UNetBlock(in_channels, n_chan(0)))
        for i in range(3):
            self.down_layers.append(UNetBlock(n_chan(i), n_chan(i+1)))
        self.bottleneck = UNetBlock(n_chan(3), n_chan(4))
        self.up_layers = nn.ModuleList([])
        for i in reversed(range(1, 4)):
            self.up_layers.append(UNetBlock(n_chan(i+1)+n_chan(i), n_chan(i)))
        self.up_layers.append(nn.Sequential(
            UNetBlock(n_chan(1)+n_chan(0), n_chan(0),),
            nn.Conv2d(n_chan(0), out_channels, 1)))

    @staticmethod
    def interp_cat(x, skip):
        x = F.interpolate(x, skip.shape[2:], mode='bilinear', align_corners=True)
        return torch.cat((x, skip), 1)

    def forward(self, x):
        skip_connections = []
        for down_layer in self.down_layers:
            x = down_layer(x)
            skip_connections.append(x)
            x = F.max_pool2d(x, 2)
        x = self.bottleneck(x)
        for up_layer in self.up_layers:
            skip = skip_connections.pop()
            x = self.interp_cat(x, skip)
            x = up_layer(x)


        return torch.sigmoid(x)




class BCEDiceLoss(nn.Module):
    def __init__(self, weight=None, size_average=True):
        super().__init__()

    def forward(self, input, target):
        pred = input.view(-1)
        truth = target.view(-1)

        # BCE loss
        bce_loss = nn.BCELoss()(pred, truth).double()

        # Dice Loss
        dice_coef = (2.0 * (pred * truth).double().sum() + 1) / (
            pred.double().sum() + truth.double().sum() + 1
        )

        return bce_loss + (1 - dice_coef)

def testu():
    img_channels = 3
    img_size = 256
    x = torch.randn((1, 3, img_size, img_size))
    #gen = Generator(img_channels, 9)
    model = ResUnet(3)
    print(model(x).shape)

testu()

model = ResUnet(3).cuda()

criterion = BCEDiceLoss()
optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)

lossminglobal = 9999999

for epoch in range(0, NUM_EPOCHS):
  print("Epoch Number : {}/{}".format(epoch+1, NUM_EPOCHS))
  print("-"*10)


  loop = tqdm(loader, leave = True)

  lossmin = 99999

  for idx, (orig_image, mask_image) in enumerate(loop):
    mask_image = mask_image.cuda()
    orig_image = orig_image.cuda()

    optimizer.zero_grad()

    output = model(orig_image)

    loss = criterion(output, mask_image)

    loss.backward()
    optimizer.step()



    if loss.item()<lossmin:
      lossmin = loss.item()




    print("Minimum Training Loss in epoch {} is: {}".format(epoch+1, lossmin))


torch.save(model.state_dict(), "newtestmodel.h5")

if (idx % VAL_STEP==0):

      lossavg = 0
      i = 1
      model.eval()
      for id, (orig_image, mask_image) in enumerate(tqdm(val_loader, leave=True)):
        orig_image = orig_image.cuda()
        mask_image = mask_image.cuda()

        output = model(orig_image)
        lossval = criterion(output, mask_image)

        if lossval<lossminglobal:
          lossminglobal = lossval
          torch.save(model.state_dict(), "testmodel.h5")

        lossavg = lossavg + lossval
        i = i + 1

      lossavg = lossavg/i

      print("Average Validation loss: {}".format(lossavg))

      model.train()

def load_checkpoint(checkpoint_file, model, optimizer, lr):
    print("=> Loading checkpoint")
    model = torch.load("newtestmodel.h5", map_location=torch.device("cuda"))



load_checkpoint("testmodel.h5", model, optimizer, LEARNING_RATE)

tifinimg = TIFF.open('/content/drive/MyDrive/Anshul files/Inria_datasets/images/austin10.tif')
inimg = tifinimg.read_image()
#inimg = cv2.imread(imgname_org)
print('Finished Reading Input image')
#inimg = cv2.cvtColor(inimg, cv2.COLOR_BGR2RGB)
img_dtype = type(inimg[0,0,0])
print(img_dtype)
(H,W,Ch) = inimg.shape
#IMG_FILL_VALUE = np.min(inimg)
IMG_FILL_VALUE = np.max(inimg)

tile_sizey=256
tile_sizex=256

(H_delta,W_delta) = 0,0
if (H % tile_sizey) != 0:
  H_delta = tile_sizey - (H % tile_sizey)
if (W % tile_sizex) != 0:
  W_delta = tile_sizex - (W % tile_sizex)

top, bottom, left, right = 0, H_delta, 0, W_delta
inimg_new =  np.ones((H+H_delta, W+W_delta,Ch), dtype=img_dtype) * IMG_FILL_VALUE

mask =  np.zeros((1, H+H_delta, W+W_delta), dtype=np.float32)

print(mask.shape)
inimg_new[:H,:W,:] = inimg

inimg_new = inimg_new/255

offsets = product(range(0, W, tile_sizex), range(0, H, tile_sizey))
imageseg = dict()

cnt = 1

for row_off,col_off in offsets:
  #print("Img:{}. (Row:Col) = ({}:{})".format(cnt,row_off,col_off))

  trainx_list = []

  col_start, col_end, row_start, row_end = col_off, col_off+tile_sizey-1, row_off, row_off+tile_sizex-1

  imgtile = inimg_new[col_start:col_end+1,row_start:row_end+1,:]

  imageseg['{}-{}'.format(row_off,col_off)] = imgtile
  trainx_list.append(imgtile)

  trainx = np.asarray(trainx_list)

  x_train_tensor = torch.Tensor(trainx).permute(0, 3, 1, 2).cuda()

  output = model(x_train_tensor[0][None, ...])*255
  print(output)
  mask[:, col_start:col_end+1,row_start:row_end+1] = output[0].detach().cpu().numpy()

  if (cnt%200==0):
    print(cnt)
  cnt=cnt+1

print(np.unique(mask))



import rasterio as rio

inds = rio.open('/content/drive/MyDrive/Anshul files/Inria_datasets/gt/austin{}.tif'.format(IMAGE_INDEX))

meta = inds.meta.copy()
meta['compress']='lzw'
meta['count'] = 1
meta['nodata'] = None
inds.close()
outds = rio.open('ResUnet_GAN_Austin{}.tif'.format(IMAGE_INDEX), 'w', **meta)
outds.write((mask[0][:5000,:5000])*255,meta['count'])
outds.close()
