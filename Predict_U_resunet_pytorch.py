# -*- coding: utf-8 -*-
"""Unetpytorchpredict.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Wyz-tLXC-LHL5ceqthNtRVx35YZ5IS21
"""

!pip install --upgrade --force-reinstall --no-deps albumentations

!pip install opencv-python-headless imgaug libtiff rasterio



from sklearn.model_selection import train_test_split
import pandas as pd
import numpy as np
import time
import sys
from itertools import product
import cv2
import os
import matplotlib.pyplot as plt
from libtiff import TIFF
import random, torch, os, numpy as np
import torch.nn as nn
import copy
from torch.utils.data import TensorDataset, DataLoader
import torch.optim as optim
from tqdm.notebook import tqdm
from torchvision.utils import save_image
from torch.nn import functional as F
from sklearn.metrics import confusion_matrix 
from sklearn.metrics import accuracy_score 
from sklearn.metrics import classification_report

import torch
import albumentations as A
from albumentations.pytorch import ToTensorV2

def mean_normalize(image):
  std_lst = []
  mean_lst = []
  for idx in range(image.shape[2]):
    std_chan = np.std(image[:,:,idx])
    mean_chan = np.mean(image[:,:,idx])
    std_lst.append(std_chan)
    mean_lst.append(mean_chan)
    
  std_img = np.array([std_lst])
  mean_img = np.array([mean_lst])
  norm_img = (image - mean_img)/std_img
  return std_img, mean_img, norm_img

IMAGE_SIZE = 256

tile_sizex = IMAGE_SIZE
tile_sizey = IMAGE_SIZE


min_feature_cnt = 1




DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

BATCH_SIZE = 1
LEARNING_RATE = 0.0002
LAMBDA_IDENTITY = 0
LAMBDA_CYCLE = 10
NUM_WORKERS = 0
LOAD_MODEL = False
SAVE_MODEL = False
CHECKPOINT_GEN_H = "genh.pth.tar"
CHECKPOINT_GEN_Z = "genz.pth.tar"
CHECKPOINT_CRITIC_H = "critich.pth.tar"
CHECKPOINT_CRITIC_Z = "criticz.pth.tar"

def load_checkpoint(checkpoint_file, model, optimizer, lr):
    print("=> Loading checkpoint")
    checkpoint = torch.load(checkpoint_file, map_location=DEVICE)
    model.load_state_dict(checkpoint["state_dict"])
    optimizer.load_state_dict(checkpoint["optimizer"])

    for param_group in optimizer.param_groups:
        param_group["lr"] = lr

# just seeds for making results reproducible.

def seed_everything(seed=42):
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
seed_everything(123)

class ResidualConv(nn.Module):
    def __init__(self, input_dim, output_dim, stride, padding):
        super(ResidualConv, self).__init__()

        self.conv_block = nn.Sequential(
            nn.BatchNorm2d(input_dim),
            nn.ReLU(),
            nn.Conv2d(
                input_dim, output_dim, kernel_size=3, stride=stride, padding=padding
            ),
            nn.BatchNorm2d(output_dim),
            nn.ReLU(),
            nn.Conv2d(output_dim, output_dim, kernel_size=3, padding=1),
        )
        self.conv_skip = nn.Sequential(
            nn.Conv2d(input_dim, output_dim, kernel_size=3, stride=stride, padding=1),
            nn.BatchNorm2d(output_dim),
        )

    def forward(self, x):

        return self.conv_block(x) + self.conv_skip(x)


class Upsample(nn.Module):
    def __init__(self, input_dim, output_dim, kernel, stride):
        super(Upsample, self).__init__()

        self.upsample = nn.ConvTranspose2d(
            input_dim, output_dim, kernel_size=kernel, stride=stride
        )

    def forward(self, x):
        return self.upsample(x)


class ResUnet(nn.Module):
    def __init__(self, channel, filters=[64, 128, 256, 512]):
        super(ResUnet, self).__init__()

        self.input_layer = nn.Sequential(
            nn.Conv2d(channel, filters[0], kernel_size=3, padding=1),
            nn.BatchNorm2d(filters[0]),
            nn.ReLU(),
            nn.Conv2d(filters[0], filters[0], kernel_size=3, padding=1),
        )
        self.input_skip = nn.Sequential(
            nn.Conv2d(channel, filters[0], kernel_size=3, padding=1)
        )

        self.residual_conv_1 = ResidualConv(filters[0], filters[1], 2, 1)
        self.residual_conv_2 = ResidualConv(filters[1], filters[2], 2, 1)

        self.bridge = ResidualConv(filters[2], filters[3], 2, 1)

        self.upsample_1 = Upsample(filters[3], filters[3], 2, 2)
        self.up_residual_conv1 = ResidualConv(filters[3] + filters[2], filters[2], 1, 1)

        self.upsample_2 = Upsample(filters[2], filters[2], 2, 2)
        self.up_residual_conv2 = ResidualConv(filters[2] + filters[1], filters[1], 1, 1)

        self.upsample_3 = Upsample(filters[1], filters[1], 2, 2)
        self.up_residual_conv3 = ResidualConv(filters[1] + filters[0], filters[0], 1, 1)

        self.output_layer = nn.Sequential(
            nn.Conv2d(filters[0], 1, 1, 1),
            nn.Sigmoid(),
        )

    def forward(self, x):
        # Encode
        x1 = self.input_layer(x) + self.input_skip(x)
        x2 = self.residual_conv_1(x1)
        x3 = self.residual_conv_2(x2)
        # Bridge
        x4 = self.bridge(x3)
        # Decode
        x4 = self.upsample_1(x4)
        x5 = torch.cat([x4, x3], dim=1)

        x6 = self.up_residual_conv1(x5)

        x6 = self.upsample_2(x6)
        x7 = torch.cat([x6, x2], dim=1)

        x8 = self.up_residual_conv2(x7)

        x8 = self.upsample_3(x8)
        x9 = torch.cat([x8, x1], dim=1)

        x10 = self.up_residual_conv3(x9)

        output = self.output_layer(x10)

        return output





class ConvLayer(nn.Sequential):
    def __init__(self, in_channels:int, out_channels:int):
        super().__init__()
        self.add_module('conv', nn.Conv2d(in_channels, out_channels,
                                           3, padding=1, bias=False))
        self.add_module('norm', nn.BatchNorm2d(out_channels))
        self.add_module('relu', nn.ReLU(inplace=True))


class UNetBlock(nn.Sequential):
    def __init__(self, in_channels:int, out_channels:int):
        super().__init__()
        self.add_module('block1', ConvLayer(in_channels, out_channels))
        self.add_module('block2', ConvLayer(out_channels, out_channels))


class UNet(nn.Module):
    def __init__(self, in_channels:int, out_channels:int, channel_base:int=64):
        super().__init__()
        self.down_layers = nn.ModuleList([])
        n_chan = lambda x: channel_base*2**x
        self.down_layers.append(UNetBlock(in_channels, n_chan(0)))
        for i in range(3):
            self.down_layers.append(UNetBlock(n_chan(i), n_chan(i+1)))
        self.bottleneck = UNetBlock(n_chan(3), n_chan(4))
        self.up_layers = nn.ModuleList([])
        for i in reversed(range(1, 4)):
            self.up_layers.append(UNetBlock(n_chan(i+1)+n_chan(i), n_chan(i)))
        self.up_layers.append(nn.Sequential(
            UNetBlock(n_chan(1)+n_chan(0), n_chan(0),),
            nn.Conv2d(n_chan(0), out_channels, 1)))

    @staticmethod
    def interp_cat(x, skip):
        x = F.interpolate(x, skip.shape[2:], mode='bilinear', align_corners=True)
        return torch.cat((x, skip), 1)

    def forward(self, x):
        skip_connections = []
        for down_layer in self.down_layers:
            x = down_layer(x)
            skip_connections.append(x)
            x = F.max_pool2d(x, 2)
        x = self.bottleneck(x)
        for up_layer in self.up_layers:
            skip = skip_connections.pop()
            x = self.interp_cat(x, skip)
            x = up_layer(x)


        return torch.sigmoid(x)



gen_Z = ResUnet(3).to(DEVICE)
#gen_H = UNet(1, 3).to(DEVICE)
opt_gen = optim.RMSprop(gen_Z.parameters(),lr=0.0001)
def load_checkpoint(checkpoint_file, model, optimizer, lr):
    print("=> Loading checkpoint")
    checkpoint = torch.load(checkpoint_file, map_location=DEVICE)
    model.load_state_dict(checkpoint["state_dict"])
    optimizer.load_state_dict(checkpoint["optimizer"])

    for param_group in optimizer.param_groups:
        param_group["lr"] = lr


load_checkpoint('/content/drive/MyDrive/Project Weights/Project Weights/ResnetGan/genz.pth.tar', gen_Z, opt_gen, LEARNING_RATE)

tifinimg = TIFF.open('/content/drive/MyDrive/Anshul files/Inria_datasets/images/austin{}.tif'.format(IMAGE_INDEX))
inimg = tifinimg.read_image()

print('Finished Reading Input image')

img_dtype = type(inimg[0,0,0])
(H,W,Ch) = inimg.shape

IMG_FILL_VALUE = np.max(inimg)

tile_sizey=256
tile_sizex=256

(H_delta,W_delta) = 0,0
if (H % tile_sizey) != 0:
  H_delta = tile_sizey - (H % tile_sizey)
if (W % tile_sizex) != 0:
  W_delta = tile_sizex - (W % tile_sizex)

top, bottom, left, right = 0, H_delta, 0, W_delta
inimg_new =  np.ones((H+H_delta, W+W_delta,Ch), dtype=img_dtype) * IMG_FILL_VALUE

mask =  np.zeros((1, H+H_delta, W+W_delta), dtype=img_dtype)

print(mask.shape)
inimg_new[:H,:W,:] = inimg

inimg_new = inimg_new/255

offsets = product(range(0, W, tile_sizex), range(0, H, tile_sizey))
imageseg = dict()

cnt = 1
  
for row_off,col_off in offsets:


  trainx_list = []
  
  col_start, col_end, row_start, row_end = col_off, col_off+tile_sizey-1, row_off, row_off+tile_sizex-1
  
  imgtile = inimg_new[col_start:col_end+1,row_start:row_end+1,:]
  
  imageseg['{}-{}'.format(row_off,col_off)] = imgtile
  trainx_list.append(imgtile)
  
  trainx = np.asarray(trainx_list)

  x_train_tensor = torch.Tensor(trainx).permute(0, 3, 1, 2).cuda()
  #print(x_train_tensor.shape)
  output = gen_Z(x_train_tensor[0][None, ...])

  mask[:, col_start:col_end+1,row_start:row_end+1] = output[0].detach().cpu().numpy()

  if (cnt%100==0):
    print(cnt)
  cnt=cnt+1

print(np.unique(mask))



import rasterio as rio  

inds = rio.open('/content/drive/MyDrive/Anshul files/Inria_datasets/gt/austin{}.tif'.format(IMAGE_INDEX))

meta = inds.meta.copy()
meta['compress']='lzw'
meta['count'] = 1
meta['nodata'] = None
inds.close()
outds = rio.open('ResUnet_GAN_Austin{}.tif'.format(IMAGE_INDEX), 'w', **meta)
outds.write((mask[0][:5000,:5000])*255,meta['count'])
outds.close()

IMAGE_INDEX = 35

