# -*- coding: utf-8 -*-
"""unet_predict.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1peybzdBI_UmsV-mZEzWeZX7EaSMASzG4
"""

!pip install rasterio libtiff

import numpy as np
from itertools import product
import rasterio as rio
import cv2
import os
from libtiff import TIFF
from libtiff import TIFFfile, TIFFimage
import time
# In[3]:
from keras.models import Model
from keras.layers import Conv2D #to add convolution layers
from keras.layers import MaxPooling2D # to add pooling layers
from keras.layers import Conv2DTranspose
from keras.layers import UpSampling2D
from keras.layers import Dropout
from keras.layers import Input
from keras.layers import BatchNormalization
from keras.layers import concatenate
from keras.optimizers import Adam
#from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau
#from keras.preprocessing.image import ImageDataGenerator
from keras import backend as K

start = time.process_time()

def iou(y_true, y_pred, smooth = 100):
    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)
    union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection
    #sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)
    iou_acc = (intersection + smooth) / (union + smooth)
    return iou_acc

# In[]:
from tensorflow.compat.v1 import ConfigProto
from tensorflow.compat.v1 import InteractiveSession

config = ConfigProto()
config.gpu_options.allow_growth = True
session = InteractiveSession(config=config)
# In[5]:

def jaccard_coef(y_true, y_pred):
    # __author__ = Vladimir Iglovikov
    intersection = K.sum(y_true * y_pred, axis=[0, -1, -2])
    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])

    jac = (intersection + smooth) / (sum_ - intersection + smooth)

    return K.mean(jac)

def jaccard_coef_int(y_true, y_pred):
    # __author__ = Vladimir Iglovikov
    y_pred_pos = K.round(K.clip(y_pred, 0, 1))

    intersection = K.sum(y_true * y_pred_pos, axis=[0, -1, -2])
    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])
    jac = (intersection + smooth) / (sum_ - intersection + smooth)
    return K.mean(jac)

# In[6]:

smooth = 1.

def dice_coef(y_true, y_pred):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)


def dice_coef_loss(y_true, y_pred):
    return -dice_coef(y_true, y_pred)

# In[6]:

def weighted_binary_crossentropy(y_true, y_pred):
    class_loglosses = K.mean(K.binary_crossentropy(y_true, y_pred), axis=[0, 1, 2])
    return K.sum(class_loglosses * K.constant(class_weights))

# In[]:
def mean_normalize_org(image):
  std_img = np.std(image)
  mean_img = np.mean(image)
  norm_img = (image - mean_img)/std_img
  return std_img, mean_img, norm_img

def mean_normalize(image):
  std_lst = []
  mean_lst = []
  for idx in range(image.shape[2]):
    std_chan = np.std(image[:,:,idx])
    mean_chan = np.mean(image[:,:,idx])
    std_lst.append(std_chan)
    mean_lst.append(mean_chan)

  std_img = np.array([std_lst])
  mean_img = np.array([mean_lst])
  norm_img = (image - mean_img)/std_img
  return std_img, mean_img, norm_img

def reverse_mean_normalize(norm, std_img, mean_img):
  image = (norm * std_img) + mean_img
  return image

# In[7]:
# To read the images in numerical order
import re
numbers = re.compile(r'(\d+)')
def numericalSort(value):
    parts = numbers.split(value)
    parts[1::2] = map(int, parts[1::2])
    return parts

Num_Epochs = 50
Image_size = 256
tile_sizex = Image_size
tile_sizey = Image_size



model_path = "/content/drive/MyDrive/model_unet_austin_new.h5"

save_tiles = False
view_tiles = False
save_pred_tile = False
view_prediction = False
use_crf = False
use_threshold = True
mask_zero_thresh = 200
apply_morph = False
#NO_DATA_VAL = -3.4e+38
#NO_DATA_VAL = 0
NO_DATA_VAL = None
DEFAULT_VAL_BCKGRND = 0
DEFAULT_VAL_FORGRND = 256
#DEFAULT_VAL_BCKGRND = -108.66666
#DEFAULT_VAL_FORGRND = 4582.908

print('Reading Input image:',imgname_org)
tifinimg = TIFF.open(imgname_org)
inimg = tifinimg.read_image()
#inimg = cv2.imread(imgname_org)
print('Finished Reading Input image')
#inimg = cv2.cvtColor(inimg, cv2.COLOR_BGR2RGB)
img_dtype = type(inimg[0,0,0])
(H,W,Ch) = inimg.shape
#IMG_FILL_VALUE = np.min(inimg)
IMG_FILL_VALUE = np.max(inimg)

(H_delta,W_delta) = 0,0
if (H % tile_sizey) != 0:
  H_delta = tile_sizey - (H % tile_sizey)
if (W % tile_sizex) != 0:
  W_delta = tile_sizex - (W % tile_sizex)

top, bottom, left, right = 0, H_delta, 0, W_delta
inimg_new =  np.ones((H+H_delta, W+W_delta,Ch), dtype=img_dtype) * IMG_FILL_VALUE
inimg_new[:H,:W,:] = inimg

instd, inmean, inimg_new = mean_normalize(inimg_new)

offsets = product(range(0, W, tile_sizex), range(0, H, tile_sizey))
imageseg = dict()
trainx_list = []
cnt = 1
view_tiles_img = view_tiles

for row_off,col_off in offsets:
  print("Img:{}. (Row:Col) = ({}:{})".format(cnt,row_off,col_off))

  col_start, col_end, row_start, row_end = col_off, col_off+tile_sizey-1, row_off, row_off+tile_sizex-1

  imgtile = inimg_new[col_start:col_end+1,row_start:row_end+1,:]

  imageseg['{}-{}'.format(row_off,col_off)] = imgtile
  trainx_list.append(imgtile)

  cnt = cnt + 1

  if save_tiles == True:
    out_img_tile = os.path.join(img_tiles_path, 'img_{}-{}.tif'.format(row_off,col_off))
#    out_img_tile = './Austin/tiles_img_new/img_{}-{}.tif'.format(row_off,col_off)
    tif_img_tile = TIFF.open(out_img_tile, mode='w')
    tif_img_tile.write_image(reverse_mean_normalize(imgtile, instd, inmean).astype(img_dtype), compression='lzw', write_rgb=True)
    TIFF.close(tif_img_tile)

  if view_tiles_img == True:
    cv2.imshow("img_{}-{}".format(row_off,col_off), cv2.cvtColor(reverse_mean_normalize(imgtile, instd, inmean).astype(img_dtype),cv2.COLOR_RGB2BGR))
    key = cv2.waitKey(0)
    cv2.destroyAllWindows()
    if key == 27:
      view_tiles_img = False

# Array of all the cropped Training sat Images
trainx = np.asarray(trainx_list)

if imgname_orgmask == None:
  (H2,W2) = (H,W)
  (H_delta2,W_delta2) = (H_delta,W_delta)
  mask_dtype = img_dtype
#  mask_dtype = np.uint8
  mask_minval = DEFAULT_VAL_BCKGRND
  mask_maxval = DEFAULT_VAL_FORGRND
#  mask_maxval = 255

num_output_classes = 1

# In[24]:

inputs = Input(trainx.shape[1:])
n_classes=1
im_sz=Image_size
n_channels=Ch
n_filters_start=32
growth_factor=2
upconv=True
class_weights=[1.0]

droprate=0.25
n_filters = n_filters_start

conv1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(inputs)
conv1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv1)
pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)

n_filters *= growth_factor
pool1 = BatchNormalization()(pool1)
conv2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool1)
conv2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv2)
pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
pool2 = Dropout(droprate)(pool2)

n_filters *= growth_factor
pool2 = BatchNormalization()(pool2)
conv3 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool2)
conv3 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv3)
pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
pool3 = Dropout(droprate)(pool3)

n_filters *= growth_factor
pool3 = BatchNormalization()(pool3)
conv4_0 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool3)
conv4_0 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv4_0)
pool4_1 = MaxPooling2D(pool_size=(2, 2))(conv4_0)
pool4_1 = Dropout(droprate)(pool4_1)

n_filters *= growth_factor
pool4_1 = BatchNormalization()(pool4_1)
conv4_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool4_1)
conv4_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv4_1)
pool4_2 = MaxPooling2D(pool_size=(2, 2))(conv4_1)
pool4_2 = Dropout(droprate)(pool4_2)

n_filters *= growth_factor
conv5 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool4_2)
conv5 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv5)

n_filters //= growth_factor
if upconv:
    up6_1 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv5), conv4_1])
else:
    up6_1 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4_1])
up6_1 = BatchNormalization()(up6_1)
conv6_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up6_1)
conv6_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv6_1)
conv6_1 = Dropout(droprate)(conv6_1)

n_filters //= growth_factor
if upconv:
    up6_2 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv6_1), conv4_0])
else:
    up6_2 = concatenate([UpSampling2D(size=(2, 2))(conv6_1), conv4_0])
up6_2 = BatchNormalization()(up6_2)
conv6_2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up6_2)
conv6_2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv6_2)
conv6_2 = Dropout(droprate)(conv6_2)

n_filters //= growth_factor
if upconv:
    up7 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv6_2), conv3])
else:
    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6_2), conv3])
up7 = BatchNormalization()(up7)
conv7 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up7)
conv7 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv7)
conv7 = Dropout(droprate)(conv7)

n_filters //= growth_factor
if upconv:
    up8 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv7), conv2])
else:
    up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2])
up8 = BatchNormalization()(up8)
conv8 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up8)
conv8 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv8)
conv8 = Dropout(droprate)(conv8)

n_filters //= growth_factor
if upconv:
    up9 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv8), conv1])
else:
    up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1])
conv9 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up9)
conv9 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv9)

conv10 = Conv2D(n_classes, (1, 1), activation='sigmoid')(conv9)

model = Model(inputs=inputs, outputs=conv10)

model.summary()

# In[25]:





def bn_act(x, act=True):
    x = keras.layers.BatchNormalization()(x)
    if act == True:
        x = keras.layers.Activation("relu")(x)
    return x

def conv_block(x, filters, kernel_size=(3, 3), padding="same", strides=1):
    conv = bn_act(x)
    conv = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(conv)
    return conv

def stem(x, filters, kernel_size=(3, 3), padding="same", strides=1):
    conv = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)
    conv = conv_block(conv, filters, kernel_size=kernel_size, padding=padding, strides=strides)

    shortcut = keras.layers.Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)
    shortcut = bn_act(shortcut, act=False)

    output = keras.layers.Add()([conv, shortcut])
    return output

def residual_block(x, filters, kernel_size=(3, 3), padding="same", strides=1):
    res = conv_block(x, filters, kernel_size=kernel_size, padding=padding, strides=strides)
    res = conv_block(res, filters, kernel_size=kernel_size, padding=padding, strides=1)

    shortcut = keras.layers.Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)
    shortcut = bn_act(shortcut, act=False)

    output = keras.layers.Add()([shortcut, res])
    return output

def upsample_concat_block(x, xskip):
    u = keras.layers.UpSampling2D((2, 2))(x)
    c = keras.layers.Concatenate()([u, xskip])
    return c

def ResUNet():
    f = [16, 32, 64, 128, 256]
    inputs = keras.layers.Input((image_size, image_size, 3))

    ## Encoder
    e0 = inputs
    e1 = stem(e0, f[0])
    e2 = residual_block(e1, f[1], strides=2)
    e3 = residual_block(e2, f[2], strides=2)
    e4 = residual_block(e3, f[3], strides=2)
    e5 = residual_block(e4, f[4], strides=2)

    ## Bridge
    b0 = conv_block(e5, f[4], strides=1)
    b1 = conv_block(b0, f[4], strides=1)

    ## Decoder
    u1 = upsample_concat_block(b1, e4)
    d1 = residual_block(u1, f[4])

    u2 = upsample_concat_block(d1, e3)
    d2 = residual_block(u2, f[3])

    u3 = upsample_concat_block(d2, e2)
    d3 = residual_block(u3, f[2])

    u4 = upsample_concat_block(d3, e1)
    d4 = residual_block(u4, f[1])

    outputs = keras.layers.Conv2D(1, (1, 1), padding="same", activation="sigmoid")(d4)
    model = keras.models.Model(inputs, outputs)
    return model






#model.compile(optimizer = Adam(lr = 0.00001), loss = 'binary_crossentropy', metrics = ['accuracy', iou])
#model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef])
#model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=['accuracy', iou, dice_coef])
#model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=[jaccard_coef, jaccard_coef_int, 'accuracy'])
model.compile(optimizer=Adam(), loss=weighted_binary_crossentropy, metrics=['accuracy', iou, dice_coef, jaccard_coef])

print('Loading weights')
model.load_weights(model_path)

model.summary()

final_imgmask = np.zeros((H+H_delta,W+W_delta),dtype=img_dtype)

# In[ ]:
# List of file names of actual Satellite images for testing
filelist_testx = imageseg.keys()
Num_test_samples = len(filelist_testx)

if os.path.exists(pred_tiles_path):
  print('Output directory exists. Deleting contents..')
  for old_file in os.listdir(pred_tiles_path):
    old_file_path = os.path.join(pred_tiles_path, old_file)
    os.remove(old_file_path)
else:
  print('Creating output directory:',pred_tiles_path)
  os.mkdir(pred_tiles_path)

for idx, fname in enumerate(filelist_testx):
    test_image_name = fname

    print('Processing tile ({}/{}): (roff-coff)=({})'.format(idx+1, Num_test_samples, test_image_name))
    # Reading the image
    im = imageseg[fname]

#    im = np.expand_dims(im, axis=0) # shape (1, x_pixels, y_pixels, n_bands)
    im = im[np.newaxis,:] # shape (1, x_pixels, y_pixels, n_bands)

    pred_mask_arr = model.predict(im)

    pred_mask = np.reshape(pred_mask_arr[0],(pred_mask_arr[0].shape[0],pred_mask_arr[0].shape[1]))

    test_mask_name = test_image_name

#    if imgname_orgmask != None:
#      # Getting the actual mask
#      actual_mask = imageseg2[test_mask_name]
#      cv2.imshow("actual mask",actual_mask)

    if save_pred_tile == True:
      out_file_name = pred_tiles_path + str(test_image_name) + '_pred.tif'

      tif_pred = TIFF.open(out_file_name, mode='w')
      tif_pred.write_image(pred_mask)
      TIFF.close(tif_pred)

    imgname_parts = test_mask_name.split('-')
    tile_w, tile_h  = int(imgname_parts[0]), int(imgname_parts[1])

    final_imgmask[tile_h:tile_h+pred_mask.shape[0],tile_w:tile_w+pred_mask.shape[1]] = (pred_mask*(mask_maxval - mask_minval)).astype(mask_dtype)

#    cv2.imshow("image", cv2.cvtColor(reverse_mean_normalize(im, instd, inmean),cv2.COLOR_RGB2BGR))
#    cv2.imshow("pred_mask",(pred_mask*(mask_maxval - mask_minval)).astype(mask_dtype))

#    cv2.imshow("final_imgmask(600x600)",final_imgmask[:600,:600])
#    cv2.imshow("actual_imgmask(600x600)",inmask[:600,:600])
#
#    key = cv2.waitKey(0)
#    if key == 27:
#      cv2.destroyAllWindows()
#      break
#    cv2.destroyAllWindows()

# In[ ]:
## Create prediction file without metadata
#out_file_name_final = './Austin/austin_gt_pred.tif'
#if os.path.exists(out_file_name_final):
#  print('Removing old file:',out_file_name_final)
#  os.remove(out_file_name_final)
#tif_pred_final = TIFF.open(out_file_name_final, mode='w')
#tif_pred_final.write_image(final_imgmask, compression='lzw')
#TIFF.close(tif_pred_final)

# In[ ]:
# Create prediction file with metadata
out_file_name_final2 = output_file_path
if os.path.exists(out_file_name_final2):
  print('Removing old file:',out_file_name_final2)
  os.remove(out_file_name_final2)

if imgname_orgmask != None:
  print('Using mask image to read metadata:',imgname_orgmask)
  inds = rio.open(imgname_orgmask)
else:
  print('Using input image to read metadata:',imgname_org)
  inds = rio.open(imgname_org)

meta = inds.meta.copy()
meta['compress']='lzw'
meta['count'] = 1
meta['nodata'] = NO_DATA_VAL
inds.close()
outds = rio.open(out_file_name_final2, 'w', **meta)
outds.write(final_imgmask[:H2,:W2],meta['count'])
outds.close()

from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report

actual = None
predicted = None

if imgname_orgmask != None:
  actual = inmask.copy()


if type(actual) != type(None) and type(predicted) != type(None):
  print('Calculating confusion matrix')
  results = confusion_matrix(actual.flatten(), predicted.flatten())
  print ('Confusion Matrix :')
  print(results)
  print ('Accuracy Score :', accuracy_score(actual.flatten(), predicted.flatten()))
  print ('Report : ')
  print (classification_report(actual.flatten(), predicted.flatten()))
else:
  print('Cannot calculate confusion matrix')

print(time.process_time() - start)
