# -*- coding: utf-8 -*-
"""cyclegan_predict.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AunbIhJ3fa4mmsUzMuxbXgflpAG3r9Nq
"""

!pip install --upgrade --force-reinstall --no-deps albumentations

!pip install opencv-python-headless imgaug libtiff rasterio

def load_checkpoint(checkpoint_file, model, optimizer, lr):
    print("=> Loading checkpoint")
    checkpoint = torch.load(checkpoint_file, map_location=DEVICE)
    model.load_state_dict(checkpoint["state_dict"])
    optimizer.load_state_dict(checkpoint["optimizer"])

    # If we don't do this then it will just have learning rate of old checkpoint
    # and it will lead to many hours of debugging \:
    for param_group in optimizer.param_groups:
        param_group["lr"] = lr

load_checkpoint(
            '/content/drive/MyDrive/gan_output/genh.pth.tar', gen_H, opt_gen, LEARNING_RATE,
        )

load_checkpoint(
    '/content/drive/MyDrive/gan_output/genz.pth.tar', gen_Z, opt_gen, LEARNING_RATE,
)

gen_Z.load_state_dict(torch.load("/content/drive/MyDrive/Project Weights/Project Weights/Unet-Gan/genz.pth.tar"))

tifinimg = TIFF.open('/content/drive/MyDrive/Anshul files/Inria_datasets/images/austin10.tif')
inimg = tifinimg.read_image()
#inimg = cv2.imread(imgname_org)
print('Finished Reading Input image')
#inimg = cv2.cvtColor(inimg, cv2.COLOR_BGR2RGB)
img_dtype = type(inimg[0,0,0])
(H,W,Ch) = inimg.shape
#IMG_FILL_VALUE = np.min(inimg)
IMG_FILL_VALUE = np.max(inimg)

tile_sizey=128
tile_sizex=128

(H_delta,W_delta) = 0,0
if (H % tile_sizey) != 0:
  H_delta = tile_sizey - (H % tile_sizey)
if (W % tile_sizex) != 0:
  W_delta = tile_sizex - (W % tile_sizex)

top, bottom, left, right = 0, H_delta, 0, W_delta
inimg_new =  np.ones((H+H_delta, W+W_delta,Ch), dtype=img_dtype) * IMG_FILL_VALUE

mask =  np.zeros((1, H+H_delta, W+W_delta), dtype=img_dtype)

print(mask.shape)
inimg_new[:H,:W,:] = inimg

inimg_new = inimg_new/255

offsets = product(range(0, W, tile_sizex), range(0, H, tile_sizey))
imageseg = dict()

cnt = 1
  
for row_off,col_off in offsets:
  #print("Img:{}. (Row:Col) = ({}:{})".format(cnt,row_off,col_off))

  trainx_list = []
  
  col_start, col_end, row_start, row_end = col_off, col_off+tile_sizey-1, row_off, row_off+tile_sizex-1
  
  imgtile = inimg_new[col_start:col_end+1,row_start:row_end+1,:]
  
  imageseg['{}-{}'.format(row_off,col_off)] = imgtile
  trainx_list.append(imgtile)
  
  trainx = np.asarray(trainx_list)

  x_train_tensor = torch.Tensor(trainx).permute(0, 3, 1, 2).cuda()
  
  output = gen_Z(x_train_tensor[0][None, ...])
  
  mask[:, col_start:col_end+1,row_start:row_end+1] = output[0].detach().cpu().numpy()

  if (cnt%200==0):
    print(cnt)
  cnt=cnt+1

np.unique(mask)

from matplotlib import pyplot
pyplot.hist(mask.flatten())

mask_new = mask[0][0:5000, 0:5000] 
print(mask_new.shape)

import rasterio as rio    

with rio.open('/content/drive/MyDrive/Anshul files/Inria_datasets/gt/austin20.tif') as src:
    ras_data = src.read()
    ras_meta = src.profile

ras_meta['compress']='lzw'
ras_meta['count'] = 1

with rio.open('outname.tif', 'w', **ras_meta) as dst:
    dst.write(mask_new, ras_meta['count'])



mask_new = mask[:, 0:5000, 0:5000]
print(mask_new.shape)
input = rasterio.open('/content/drive/MyDrive/Anshul files/Inria_datasets/gt/austin20.tif')

print(input.shape)
meta = input.meta.copy()
meta['compress']='lzw'
meta['count'] = 1
out = rasterio.open('check.tif', 'w', **meta)
out.write(mask_new[0].astype(np.float32), meta['count'])

with rasterio.Env():

    # Write an array as a raster band to a new 8-bit file. For
    # the new file's profile, we start with the profile of the source
    profile = src.profile

    # And then change the band count to 1, set the
    # dtype to uint8, and specify LZW compression.
    profile.update(
        dtype=rasterio.uint8,
        count=1,
        compress='lzw')

    with rasterio.open('example.tif', 'w', **profile) as dst:
        dst.write(array.astype(rasterio.uint8), 1)



mask = np.moveaxis(mask, [0, 1, 2], [2, 0, 1])

import cv2

img2 = cv2.merge((mask_new,mask_new,mask_new))

from PIL import Image
im=Image.fromarray(img2*255)
im.save("your_mask.tif")

tifinmask = TIFF.open('/content/drive/MyDrive/Anshul files/Inria_datasets/gt/austin20.tif')
inmask = tifinmask.read_image()
#inmask = cv2.imread(imgname_orgmask)
mask_dtype = type(inmask[0,0])
(H2,W2) = inmask.shape
(H_delta2,W_delta2) = 0,0
if (H2 % tile_sizey) != 0:
  H_delta2 = tile_sizey - (H2 % tile_sizey)
if (W2 % tile_sizex) != 0:
  W_delta2 = tile_sizex - (W2 % tile_sizex)

top2, bottom2, left2, right2 = 0, H_delta2, 0, W_delta2
inmask_new =  cv2.copyMakeBorder(inmask, top2, bottom2, left2, right2, cv2.BORDER_CONSTANT, value=0)

mask_minval = np.min(inmask_new)
mask_maxval = np.max(inmask_new)

inmask_new = inmask_new / (mask_maxval - mask_minval)

inmask_new.shape

actual = inmask_new.flatten()
predicted = mask.flatten()

from sklearn.metrics import confusion_matrix 
from sklearn.metrics import accuracy_score 
from sklearn.metrics import classification_report 

print('Calculating confusion matrix')
results = confusion_matrix(actual.flatten(), predicted.flatten())
print ('Confusion Matrix :')
print(results)
print ('Accuracy Score :', accuracy_score(actual.flatten(), predicted.flatten()))
print ('Report : ')
print (classification_report(actual, predicted))



a.shape

print('Calculating confusion matrix')
results = confusion_matrix(actual.flatten(), predicted.flatten())
print ('Confusion Matrix :')
print(results)
print ('Accuracy Score :', accuracy_score(actual.flatten(), predicted.flatten()))
print ('Report : ')
print (classification_report(actual.flatten(), predicted.flatten()))